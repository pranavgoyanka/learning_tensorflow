{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavgoyanka/learning_tensorflow/blob/master/Copy_of_Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "outputId": "4f9b8757-6bf0-4df6-bfe9-4796cd6f27d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "outputId": "a8ac75b9-71a8-4bf3-c75d-e007e6c474b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-30 08:00:51--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.214.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "\r          /tmp/ince   0%[                    ]       0  --.-KB/s               \r         /tmp/incep   9%[>                   ]   8.01M  37.5MB/s               \r        /tmp/incept  54%[=========>          ]  45.62M   110MB/s               \r/tmp/inception_v3_w 100%[===================>]  83.84M   143MB/s    in 0.6s    \n",
            "\n",
            "2020-01-30 08:00:52 (143 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "outputId": "2932dc9c-eff4-4286-df12-97403b952b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "outputId": "84835fe6-6265-49cf-d49a-b2b1153289f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "outputId": "7b20fc37-4eb7-4167-96b6-8a1d884f2f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-30 08:27:24--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   185MB/s    in 0.8s    \n",
            "\n",
            "2020-01-30 08:27:25 (185 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-01-30 08:27:27--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.194.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-01-30 08:27:27 (78.0 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "outputId": "7d7f5fad-1725-49ee-a390-9577c722f51d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir = '/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "7b950795-c034-4d4a-fbc3-9589a4804f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, \n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir, \n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "a7d7541c-5e40-40b2-86cc-abd77e906d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0215 - acc: 0.9949 - val_loss: 0.2190 - val_acc: 0.9727\n",
            "Epoch 2/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0361 - acc: 0.9919 - val_loss: 0.1518 - val_acc: 0.9737\n",
            "Epoch 3/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0290 - acc: 0.9944 - val_loss: 0.0455 - val_acc: 0.9919\n",
            "Epoch 4/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0267 - acc: 0.9934 - val_loss: 0.0795 - val_acc: 0.9889\n",
            "Epoch 5/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0122 - acc: 0.9970 - val_loss: 0.1556 - val_acc: 0.9808\n",
            "Epoch 6/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0401 - acc: 0.9888 - val_loss: 0.1641 - val_acc: 0.9858\n",
            "Epoch 7/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0279 - acc: 0.9935 - val_loss: 0.4292 - val_acc: 0.9575\n",
            "Epoch 8/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0456 - acc: 0.9913 - val_loss: 0.2478 - val_acc: 0.9706\n",
            "Epoch 9/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0235 - acc: 0.9930 - val_loss: 0.1383 - val_acc: 0.9879\n",
            "Epoch 10/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0189 - acc: 0.9934 - val_loss: 0.2717 - val_acc: 0.9646\n",
            "Epoch 11/100\n",
            "Epoch 1/100\n",
            "100/100 - 24s - loss: 0.0162 - acc: 0.9960 - val_loss: 0.4917 - val_acc: 0.9555\n",
            "Epoch 12/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0320 - acc: 0.9924 - val_loss: 0.2531 - val_acc: 0.9727\n",
            "Epoch 13/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0114 - acc: 0.9970 - val_loss: 0.2991 - val_acc: 0.9656\n",
            "Epoch 14/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0144 - acc: 0.9955 - val_loss: 0.8149 - val_acc: 0.9524\n",
            "Epoch 15/100\n",
            "Epoch 1/100\n",
            "100/100 - 27s - loss: 0.0255 - acc: 0.9924 - val_loss: 0.8325 - val_acc: 0.9423\n",
            "Epoch 16/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0245 - acc: 0.9924 - val_loss: 0.7087 - val_acc: 0.9524\n",
            "Epoch 17/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0058 - acc: 0.9969 - val_loss: 0.2459 - val_acc: 0.9798\n",
            "Epoch 18/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0206 - acc: 0.9959 - val_loss: 0.3720 - val_acc: 0.9676\n",
            "Epoch 19/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0056 - acc: 0.9980 - val_loss: 1.0091 - val_acc: 0.9393\n",
            "Epoch 20/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0090 - acc: 0.9980 - val_loss: 0.4476 - val_acc: 0.9595\n",
            "Epoch 21/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0116 - acc: 0.9959 - val_loss: 1.1115 - val_acc: 0.9352\n",
            "Epoch 22/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0130 - acc: 0.9970 - val_loss: 1.3814 - val_acc: 0.9312\n",
            "Epoch 23/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0252 - acc: 0.9950 - val_loss: 1.0298 - val_acc: 0.9413\n",
            "Epoch 24/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0211 - acc: 0.9949 - val_loss: 0.2917 - val_acc: 0.9686\n",
            "Epoch 25/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0048 - acc: 0.9980 - val_loss: 0.4545 - val_acc: 0.9595\n",
            "Epoch 26/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0040 - acc: 0.9975 - val_loss: 0.7650 - val_acc: 0.9565\n",
            "Epoch 27/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0105 - acc: 0.9970 - val_loss: 0.3751 - val_acc: 0.9646\n",
            "Epoch 28/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0191 - acc: 0.9975 - val_loss: 0.3173 - val_acc: 0.9737\n",
            "Epoch 29/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0115 - acc: 0.9985 - val_loss: 0.5752 - val_acc: 0.9605\n",
            "Epoch 30/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0262 - acc: 0.9954 - val_loss: 0.3000 - val_acc: 0.9757\n",
            "Epoch 31/100\n",
            "Epoch 1/100\n",
            "100/100 - 26s - loss: 0.0194 - acc: 0.9960 - val_loss: 0.8183 - val_acc: 0.9494\n",
            "Epoch 32/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0093 - acc: 0.9975 - val_loss: 0.7469 - val_acc: 0.9565\n",
            "Epoch 33/100\n",
            "Epoch 1/100\n",
            "100/100 - 25s - loss: 0.0269 - acc: 0.9950 - val_loss: 0.5898 - val_acc: 0.9615\n",
            "Epoch 34/100\n",
            "Epoch 1/100\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "100/100 - 26s - loss: 0.0030 - acc: 0.9995 - val_loss: 0.6718 - val_acc: 0.9575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "outputId": "c53a78e2-9de0-4380-f601-dba09bbdf78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDOrvy_CrVwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}